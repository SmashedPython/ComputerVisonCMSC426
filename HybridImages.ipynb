{"cells":[{"cell_type":"markdown","metadata":{"id":"Jf-_uA8P5Hf7"},"source":["Assignment 1:\n","\n","Name:\n","\n","UID:\n","\n","Please submit to Gradescope\n","- a PDF containing all outputs (by executing **Run all**)\n","- your ipynb notebook containing all the code\n","\n","I understand the policy on academic integraty (collaboration and the use of online material).\n","Please sign your name here:\n"]},{"cell_type":"markdown","metadata":{"id":"9ftoiwAo45n5"},"source":["# Part A: Hybrid Image (25 Points)"]},{"cell_type":"markdown","metadata":{"id":"tJikaY9ICDYH"},"source":["## Overview\n","\n","A hybrid image is the sum of a *low-pass filtered* version of the one image and a *high-pass filtered* version of a second image. There is a free parameter, which can be tuned for each image pair, which controls how much high frequency to remove from the first image and how much low frequency to leave in the second image. This is called the “cutoff-frequency”. In the paper it is suggested to use two cutoff frequencies (one tuned for each image) and you are free to try that, as well. In the starter code, the cutoff frequency is controlled by changing the standard deviation of the Gausian filter used in constructing the hybrid images. [This](https://drive.google.com/uc?id=187FjBJLwnYXhylx08Vdh1SAA3AO-imYv) is the sample example.\n","\n","NOTE:\n","\n","1. Reading [this](https://stanford.edu/class/ee367/reading/OlivaTorralb_Hybrid_Siggraph06.pdf) will help in understanding Part A.\n","\n","2. You can use any image processing libraries of your choice such as skimage or cv2; in python.\n","\n","We provided 7 pairs of aligned images. The alignment is important because it affects the perceptual grouping (read the paper for details). We encourage you to create additional examples (e.g. change of expression, morph between different objects, change over time, etc.).\n","\n","You are required to provide **THREE hybrid image results**. Choose ONE of the results, and use it to provide answers to the following **FOUR sub-parts** mentioned in the write-up."]},{"cell_type":"markdown","metadata":{},"source":["# Dependencies\n","```\n","pip3 install opencv-python numpy pillow matplotlib gdown\n","```"]},{"cell_type":"markdown","metadata":{"id":"WR0sjl-f6qkm"},"source":["## Data\n","\n","**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2483,"status":"ok","timestamp":1675890827373,"user":{"displayName":"Hadi Alzayer","userId":"17365285222702044199"},"user_tz":300},"id":"0uWzKA6i68ls","outputId":"b42339a4-4db5-4564-caa5-4626d8944f52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1KTDxPAkQam29YKtoX5dKPnLKpUOWCanC\n","To: /content/hybrid_pyramid_input.zip\n","\r  0% 0.00/2.19M [00:00<?, ?B/s]\r100% 2.19M/2.19M [00:00<00:00, 102MB/s]\n","Archive:  /content/hybrid_pyramid_input.zip\n","   creating: /content/data/\n","  inflating: /content/data/Afghan_girl_before.jpg  \n","  inflating: /content/data/motorcycle.bmp  \n","  inflating: /content/data/cat.bmp   \n","  inflating: /content/data/makeup_before.jpg  \n","  inflating: /content/data/fish.bmp  \n","  inflating: /content/data/bicycle.bmp  \n","  inflating: /content/data/makeup_after.jpg  \n","  inflating: /content/data/plane.bmp  \n","  inflating: /content/data/marilyn.bmp  \n","  inflating: /content/data/dog.bmp   \n","  inflating: /content/data/Afghan_girl_after.jpg  \n","  inflating: /content/data/submarine.bmp  \n","  inflating: /content/data/bird.bmp  \n","  inflating: /content/data/einstein.bmp  \n"]}],"source":["# Download Data -- run this cell only one time per runtime\n","!gdown 1KTDxPAkQam29YKtoX5dKPnLKpUOWCanC\n","!unzip \"/content/hybrid_pyramid_input.zip\" -d \"/content/\""]},{"cell_type":"markdown","metadata":{"id":"g1DBek-_Btwj"},"source":["## Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeXJU9eHmzMb"},"outputs":[],"source":["# Helper Functions\n","def read_image(image_path):\n","    \"\"\"\n","    :param image_path: path to the image\n","    :return: floating representation of the image\n","    \"\"\"\n","    # TODO: YOUR CODE HERE\n","    return image\n","\n","def gaussian_2D_filter(size, cutoff_frequency):\n","    \"\"\"\n","    :param size: tuple (width, height) that decides the filter size\n","    :param cutoff_frequency: hyperparameter to control the variance of the filter\n","    :return: 2D gaussian filter with the desired size, and variance scaled by cutoff_frequency\n","    Hint: make sure the filter sums up to one\n","    Do NOT use scipy's API to get the filter. Please just use numpy to implement the Gaussian equation.\n","    \"\"\"\n","    # TODO: YOUR CODE HERE\n","    return filter\n","\n","def imgfilter(image, filter):\n","    \"\"\"\n","    :param image: input image to apply the filter on\n","    :param filter: to apply on the image\n","    :return: apply the filter by convolving\n","    Do NOT use for loops. See how to convolve with scipy or numpy\n","    \"\"\"\n","    # TODO: YOUR CODE HERE\n","    return output\n","\n","def log_mag_FFT(image):\n","    \"\"\"\n","    :param image: float matrix representation of the image\n","    :return: log of the magnitude of the FFT of the image\n","    HINT: You may use np.log(np.abs(np.fft.fftshift(np.fft.fft2(image)))) to achieve it.\n","    NOTE1: numpy fft2 would require you to convert the image to greyscale for it to work properly.\n","    NOTE2: To make greyscale, you may use either `grey = R*0.3 + G*0.59 + B*0.11` or `cv2.cvtColor`.\n","    \"\"\"\n","    # TODO: YOUR CODE HERE\n","    return output\n","\n","def vis_hybrid_image(hybrid_image):\n","  scales = 5\n","  scale_factor = 0.5\n","  padding = 5\n","  original_height = hybrid_image.shape[0]\n","  num_colors = hybrid_image.shape[2] # counting how many color channels the input has\n","  output = hybrid_image\n","  cur_image = hybrid_image\n","\n","  for i in range(2, scales):\n","      # add padding\n","      output = np.concatenate((output, np.ones((original_height, padding, num_colors), dtype=int)), axis=1)      \n","      # dowsample image;\n","      width = int(cur_image.shape[1] * scale_factor)\n","      height = int(cur_image.shape[0] * scale_factor)\n","      dim = (width, height)\n","      cur_image = cv2.resize(cur_image, dim, interpolation = cv2.INTER_LINEAR)\n","      # pad the top and append to the output\n","      tmp = np.concatenate((np.ones((original_height-cur_image.shape[0], cur_image.shape[1], num_colors)), cur_image), axis=0)\n","      output = np.concatenate((output, tmp), axis=1)\n","  \n","  output = (output * 255).astype(np.uint8)\n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9F0nOPhWn95d"},"outputs":[],"source":["# Import necessary packages here\n","import cv2\n","import numpy as np\n","\n","# the images downloaded above should be available under /content/data\n","# use the file directory on the left to navigate\n","image_path1 = ?  # TODO choose the first image\n","image_path2 = ?  # TODO choose the second image\n","\n","image_1 = read_image(image_path1)\n","image_2 = read_image(image_path2)\n","\n","# NOTE: the two images should have the same shape\n","\n","# YOUR CODE HERE: TUNE cutoff_frequency\n","cutoff_frequency = ?\n","filter_size = cutoff_frequency*4+1\n","\"\"\"cutoff_frequency is the standard deviation, in pixels, of the\n","Gaussian blur that will remove the high frequencies from one image (image_1) and\n","remove the low frequencies from another image (image_2) (to do so, subtract a blurred\n","version from the original version). You will want to tune this for every image pair to get the best results.\"\"\"\n","\n","filter = gaussian_2D_filter((filter_size, filter_size), cutoff_frequency)\n","plt.imshow(filter)\n","\n","\"\"\"Use imgfilter() to create 'low_frequencies' and 'high_frequencies' and then combine them to create 'hybrid_image'.\n","Remove the high frequencies from image_1 by blurring it. The amount of blur that works best will vary with different image pairs.\"\"\"\n","\n","blurred_image1 = imgfilter(image_1, filter=filter)\n","blurred_image2 = imgfilter(image_2, filter=filter)\n","\n","# YOUR CODE HERE.\n","low_frequencies = ?\n","\n","\"\"\"Remove the low frequencies from image_2. The easiest way to do this is to\n","subtract a blurred version of image_2 from the original version of image_2.\n","This will give you an image centered at zero with negative values.\"\"\"\n","\n","# YOUR CODE HERE\n","high_frequencies = ?\n","\n","\"\"\"Combine the high frequencies and low frequencies to obtain hybrid_image.\"\"\"\n","# YOUR CODE HERE\n","hybrid_image= ?\n","\n","\"\"\"Firstly, visualize image_1, low_frequencies of image_1, image_2, high_frequencies of image_2, and the hybrid image.\"\"\"\n","# YOUR CODE HERE.\n","# hint: you may use plt.subplots and add title to each subplot\n","\n","\n","\"\"\"Secondly, also visualize log magnitude of Fourier Transform of the above.\"\"\"\n","FFT_image = ?\n","# YOUR CODE HERE.\n","# hint: implement and use the helper function above `log_mag_FFT()`\n","# hint: In plt's `imshow()`, you can set the `vmin` and `vmax` to have a proper range to visualize Fourier magnitude.\n","\n","\"\"\"Thirdly, visualize hybrid_image_scale using helper function `vis_hybrid_image()`.\n","  Lastly, save all your outputs.\"\"\"\n","# YOUR CODE HERE.\n"]},{"cell_type":"markdown","metadata":{"id":"zmN8MtK2mOUz"},"source":["## **Write-up**\n","\n","\n","1.   Provide the original and filtered images.\n","2.   Provide the the hybrid image and hybrid_image_scale using given helper function *vis_hybrid_image*.\n","3.   Log magnitude of the Fourier transform of the two original images, the filtered images, and the hybrid image.\n","4.   Briefly explain how this works, using your favorite results as illustrations."]},{"cell_type":"markdown","metadata":{"id":"I06DhqYI4YI7"},"source":["**Include your write-up here**"]},{"cell_type":"markdown","metadata":{"id":"UurFy8hB5BeP"},"source":["# Part B: Pyramid Image (25 Points)"]},{"cell_type":"markdown","metadata":{"id":"baagTPK5aa9r"},"source":["## Overview\n","Choose an image that has interesting variety of textures (from Flickr or your own images). The images should be atleast 640X480 pixels and converted to grayscale. Write code for a Gaussian and Laplacian pyramid of level N (use for loops). In each level, the resolution should be reduced by a factor of 2. Show the pyramids for your chosen image in your write-up. Here is an [example](https://drive.google.com/uc?id=17Y287EA-GJ2z0wtm_M7StIWsXyFeHvrz)."]},{"cell_type":"markdown","metadata":{"id":"qWCfxrUA7LNb"},"source":["## Data\n","\n","**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5aF6Biq7LvQ"},"outputs":[],"source":["# Download Data -- run this cell only one time per runtime\n","!gdown 1KTDxPAkQam29YKtoX5dKPnLKpUOWCanC\n","!unzip \"/content/hybrid_pyramid_input.zip\" -d \"/content/\""]},{"cell_type":"markdown","metadata":{"id":"cUgcCzJRAQJ1"},"source":["## Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywdGq5E55thm"},"outputs":[],"source":["# Populate Helper Functions:\n","\n","def pyramidsGL(image, num_levels):\n","  ''' Creates Gaussian (G) and Laplacian (L) pyramids of level \"num_levels\" from image im.\n","  G and L are list where G[i], L[i] stores the i-th level of Gaussian and Laplacian pyramid, respectively. \n","  NOTE: you may use cv2.GaussianBlur and cv2.resize in this function'''\n","  # YOUR CODE HERE\n","  return G, L\n","\n","def displayPyramids(G, L):\n","  '''Role of this function is to display intensity and Fast Fourier Transform (FFT) images of pyramids.\n","  NOTE: You may re-use your helper function  \"log_mag_FFT\" to compute this.'''\n","  # YOUR CODE HERE\n","  return\n","\n","def reconstructLaplacianPyramid(L, smallest_g):\n","  '''Given a Laplacian Pyramid L, reconstruct an image img.\n","     smallest_g should be the smallest scale of the gaussian pyramid (i.e. G[-1])\n","     NOTE: you may use cv2.resize in this function\n","  '''\n","  assert L[-1].shape == smallest_g.shape\n","  # YOUR CODE HERE\n","  return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e60BvZg5Nsh"},"outputs":[],"source":["\"\"\"\n","Steps:\n","1. Load an image im.\n","2. Call function pyramidsGL with image and num_levels = 5\n","3. Call function displayPyramids with G, L\n","4. Call function reconstructLaplacianPyramid with the generated L and ONLY the smallest scale of G.\n","5. Display the original image and reconstructed image side by side.\n","6. Compute reconstruction error with L2 norm and print the error value.\n","\"\"\"\n","\n","# TODO: YOUR CODE HERE\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8AmYt5Vu9BGq"},"source":["## **Write-up**\n","\n","1. (10 Points) Display a Gaussian and Laplacian pyramid of level 5 (using your code). It should be formatted similar to [this](https://drive.google.com/file/d/1mAommQeJsp7WS8QCrZRcr8cQiltPPOh2/view?usp=sharing) figure.\n","\n","2. (10 Points) Display the FFT amplitudes of your Gaussian/Laplacian pyramids Appropriate display ranges (from 0 to 1) should be chosen so that the changes in frequency in different levels of the pyramid are clearly visible. Explain  what the Laplacian and Gaussian pyramids are doing in terms of frequency. [This](https://drive.google.com/file/d/1BqTPKq6Mqqxl5jNNPkvx4JOA5MRgVq08/view?usp=sharing) looks like the expected output.\n","\n","3. (5 Points) Image Reconstruction\n"]},{"cell_type":"markdown","metadata":{"id":"lRUDQ9Xk5e3v"},"source":["**Include your write-up here**"]}],"metadata":{"colab":{"provenance":[{"file_id":"1WcxVo4jANBJl39Kca7mbgXrJzSUO7oM6","timestamp":1707076506344},{"file_id":"1BktGJlr0DZU3y2Jd4yaTq6ZK14FFQEA0","timestamp":1675746385152}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
